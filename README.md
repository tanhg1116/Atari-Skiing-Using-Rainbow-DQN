# Undergraduate-Y3S2-Atari-Skiing-Using-Deep-Q-Network-Rainbow
Author: Ng Zheng Jue, Ng Rui Qi, Ong Ming Jie, Tan Hong Guan

* This is a project developed in undergraduate Year 3 - Semester 2
* This repository consists of solving a control movement problem using Deep Reinforcement Learning. The deep learning architecture used is Deep Q network that trained using Rainbow as we are dealing with the deterministic action
* At the same time, we analyze the effect of applying imitation learning in the Atari Skiing problem, the demonstration can be shown at [youtube]
* This repository consists of
  * 1 Jupyter Notebook file ï¼ˆskiing.ipynb) that consists of overall experimental design, development of method including training and evaluating the deep learning model and lastly the overall conclusion of the result obtained.
  * 3 python file (model.py, memory.py, agent.py)
  * Image folder to store image for the jupyter notebook file
 
## Introduction
In this experiment, we delve into the application of RL to the challenging Gym Skiing Atari environment, seeking to formulate the RL problem and design experiments to gauge the learning capabilities of a Deep Q-Network (DQN) model with __imitation learning__ by using the episode generated by heuristic agent to train the DQN. 

The formulation of the RL problem involves defining the state space, action space, and reward structure to guide the learning process effectively. The state, action and reward of the Skiing Environment is as follows:
* The state at each step, $s_t$ is represented as a cropped gray scale image with shape = (130, 144). To let the DQN model have the previous state information, continuous 4 states with shape (4,130,144) is passed to the DQN model to obtain the action.

* The agent has 3 possible actions and it can perform 1 action at each step, $a_t$. Since the action is discrete, the selection for DNN will be DQN as only single forward pass is needed to obtain an action. The action value and its corresponding meaning is as follows:

| Value | Meaning |
|:-:|:-:|
| 0     | NOOP    |
| 1     | RIGHT   |
| 2     | LEFT    |

* The reward is always -1 if the agent does not reach the goal state, and ~ -450 penalty given at the end of the game if the agent does not pass a flag in the game. In the game, there is total of 20 pair of flags. For example, if the agent does not pass 10 pairs of flag in an episode, -4500 penalty will only be given at the end of the game
